{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from PPOAgent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WrapperAtari(gym.make('MontezumaRevengeNoFrameskip-v4'))\n",
    "input_shape = env.observation_space.shape\n",
    "action_dim = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "device = 'cpu'\n",
    "checkpoint = 10000\n",
    "n_env = 128\n",
    "trials = 9\n",
    "steps = 128\n",
    "gamma = \"0.998,0.99\"   #0.99\n",
    "beta = 0.001\n",
    "batch_size = 512\n",
    "trajectory_size = 16384\n",
    "ppo_epochs = 4\n",
    "lr = 0.0001\n",
    "actor_loss_weight = 1\n",
    "critic_loss_weight = 0.5\n",
    "motivation_lr = 0.0001\n",
    "motivation_eta = 1\n",
    "num_threads = 4\n",
    "agent = Agent((4, 96, 96), \n",
    "                  action_dim,\n",
    "                  trajectory_size,\n",
    "                  batch_size,\n",
    "                  n_env,\n",
    "                  device,\n",
    "                  lr,\n",
    "                  actor_loss_weight,\n",
    "                  critic_loss_weight,\n",
    "                  beta,\n",
    "                  gamma,\n",
    "                  ppo_epochs,\n",
    "                  motivation_lr,\n",
    "                  motivation_eta,)\n",
    "agent.load('./models/FinalModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 96, 96])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "state0 = torch.tensor(env.reset(), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "next_state, reward, done, _ = env.step(0)\n",
    "print(state0.shape)\n",
    "predicted_code, target_code = agent.network.rnd_model(state0)\n",
    "print(predicted_code.shape)\n",
    "df = pd.DataFrame(predicted_code.cpu().detach().numpy())\n",
    "df = pd.concat(\n",
    "    [df, pd.DataFrame(target_code.cpu().detach().numpy())]\n",
    ")\n",
    "# df = df.append(pd.DataFrame(target_code.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rnd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rnd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rooms</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.279252</td>\n",
       "      <td>0.039838</td>\n",
       "      <td>0.691603</td>\n",
       "      <td>0.101066</td>\n",
       "      <td>0.568608</td>\n",
       "      <td>-0.693727</td>\n",
       "      <td>0.360421</td>\n",
       "      <td>-0.491851</td>\n",
       "      <td>0.231372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015328</td>\n",
       "      <td>-0.049474</td>\n",
       "      <td>0.595085</td>\n",
       "      <td>0.504615</td>\n",
       "      <td>0.054548</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>0.591273</td>\n",
       "      <td>-0.264661</td>\n",
       "      <td>-0.543385</td>\n",
       "      <td>-0.181619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rooms         0         1         2         3         4         5  \\\n",
       "0      0 -0.279252  0.039838  0.691603  0.101066  0.568608 -0.693727   \n",
       "\n",
       "          6         7         8  ...       502       503       504       505  \\\n",
       "0  0.360421 -0.491851  0.231372  ... -0.015328 -0.049474  0.595085  0.504615   \n",
       "\n",
       "        506       507       508       509       510       511  \n",
       "0  0.054548  0.020581  0.591273 -0.264661 -0.543385 -0.181619  \n",
       "\n",
       "[1 rows x 513 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2793,  0.0398,  0.6916,  0.1011,  0.5686, -0.6937,  0.3604, -0.4919,\n",
       "          0.2314, -0.2187, -0.4475, -0.4077, -0.2762,  0.1435,  0.3160,  0.8807,\n",
       "         -1.0441,  0.5600,  1.0643,  0.0085,  0.4775,  0.4188, -0.6717, -0.4647,\n",
       "          0.2623,  0.1821,  0.7352,  0.6931,  0.4281, -0.2625,  0.2115, -0.4121,\n",
       "         -0.3861, -0.0716, -0.3771,  0.7895, -0.0402, -0.7534, -0.0533, -0.6117,\n",
       "          0.0588, -0.5517, -0.0312, -0.5792, -0.0309,  0.0980,  0.4787, -0.1801,\n",
       "          0.2111, -0.2296, -0.3100,  0.8771,  0.7352, -0.6978, -0.3292, -0.3820,\n",
       "         -0.3624,  0.1300,  0.5106,  0.3092,  0.3104, -0.5641, -0.2975, -0.4029,\n",
       "         -0.6617,  0.2780,  0.9124,  0.6571, -0.4559, -0.1465,  0.4567, -0.4319,\n",
       "          0.2537, -0.0578,  0.1842,  0.2591,  0.5514,  0.0107,  0.2335,  0.2343,\n",
       "          0.3548,  0.3561, -0.1307, -0.1487, -0.4231,  0.7446,  0.1137,  0.2781,\n",
       "         -0.7559, -0.0667,  0.1596,  0.3081, -0.1531,  0.1964, -0.2134,  0.0858,\n",
       "          0.0938,  0.2340,  0.5398,  0.1504,  0.3026, -1.0938,  0.4325, -0.1151,\n",
       "         -0.7015, -0.3480,  0.2184,  0.1019,  0.7399, -0.0959, -0.3956,  0.4287,\n",
       "         -0.5090, -0.2718, -0.7914,  0.2029,  0.2717, -0.6126, -0.3714,  0.2249,\n",
       "          0.0486,  0.6147, -0.0620,  0.2313,  0.3613,  0.4529, -0.1994,  0.5585,\n",
       "         -0.2514,  0.6287,  0.0502, -0.2962, -0.2647,  0.6123, -0.0435, -0.4911,\n",
       "         -0.1408, -0.2405,  0.0999, -0.3154, -0.5265,  0.2424,  0.2638, -0.3989,\n",
       "          0.2529, -0.0524, -0.3194, -0.8983,  0.0877,  0.7170,  0.0498,  0.9213,\n",
       "          0.5077, -0.0064, -0.1278,  0.3863,  0.1233,  0.3311, -0.3654, -0.1091,\n",
       "          0.3533, -0.7777, -0.9071, -0.2444,  1.3375, -0.9720, -0.0235, -0.0923,\n",
       "         -0.0026,  0.5121, -0.0496, -0.3345, -0.2671,  0.0126, -0.1804,  0.9800,\n",
       "         -0.3466, -0.2540,  0.5293, -0.1460,  0.0786, -0.4163, -0.2286,  0.3942,\n",
       "         -0.3989, -0.4937,  0.2896,  0.6950,  0.0900, -0.1883, -0.5067, -0.2813,\n",
       "          0.3158, -0.1332,  0.6041, -0.1036, -0.0051, -0.4011, -0.3964,  0.0802,\n",
       "          0.0043,  0.0725, -0.8761,  0.3313, -0.1436,  0.1838, -0.2227,  0.1656,\n",
       "         -0.2740,  0.6794,  0.3453,  0.0172,  0.6542, -0.5087,  0.6720,  0.3068,\n",
       "          0.0038, -0.3605,  0.5694, -0.2692, -0.1268, -0.3188,  0.5892, -0.3144,\n",
       "          0.3214,  0.8602,  0.5254, -0.1004, -0.4264, -0.1171, -0.4330,  0.0145,\n",
       "         -0.3379,  0.5304,  0.2464, -1.1653,  0.6474,  0.3884, -0.3293,  0.2573,\n",
       "         -0.4500,  0.3201,  0.3916,  0.1989, -0.2685, -0.6357, -0.0468, -0.2845,\n",
       "         -0.7102,  0.8606, -0.4063, -0.0606, -0.2392, -0.0808,  0.1851,  0.5309,\n",
       "         -0.9199,  0.7588, -0.5251,  0.2804, -0.0614,  0.2804, -0.8092,  0.4470,\n",
       "          0.4952, -0.2587, -0.0788, -0.1602,  0.9516, -0.2229,  0.0821,  0.1095,\n",
       "          0.0059, -0.8427,  0.2002,  0.0822,  1.1039,  0.6148, -0.1890,  0.4024,\n",
       "         -0.3860,  0.5035,  0.2180,  0.2389,  0.3010, -1.0321, -0.3152, -0.0056,\n",
       "         -0.4709, -0.1643,  0.0617,  0.3034, -0.3595, -0.6804,  0.3801,  0.5396,\n",
       "         -0.2116, -0.3702, -0.2604, -0.2985, -0.4670,  0.4162,  0.8644, -0.5797,\n",
       "          0.7055, -0.4552,  0.7431,  0.2255, -0.6097,  1.1563, -0.4508,  0.2629,\n",
       "         -0.6362, -0.2432,  0.7556, -0.4495, -0.0293,  0.1539, -0.0888, -0.9298,\n",
       "          0.2504, -0.3253, -0.2551, -0.6164,  0.6105, -0.2888,  0.0095, -0.2917,\n",
       "         -0.2635,  0.1969,  0.1609, -0.0134,  0.0730, -0.0348, -0.0157,  0.2663,\n",
       "         -0.4788,  0.0543,  0.7177, -0.2207, -0.5701, -0.1117, -0.2485,  0.2873,\n",
       "          0.0792,  0.6673,  0.8151, -0.5047,  0.3962, -0.0169,  0.3683, -0.0862,\n",
       "         -0.3237,  0.0998, -0.1044,  0.0167,  0.1240, -0.0637, -0.6850,  0.4467,\n",
       "          0.3624, -0.2387, -0.1689, -0.3685, -0.1593, -0.5671,  0.4911,  0.5550,\n",
       "          0.3745,  0.3744, -0.2876, -0.4038, -0.4316, -0.1220, -0.2962, -0.0736,\n",
       "          0.9109, -0.2841, -0.5263, -1.0001, -0.7210, -0.3436, -0.9891,  0.0744,\n",
       "          0.4604,  0.1181, -0.0498,  0.2739,  0.2426,  0.2889,  0.2104,  0.1952,\n",
       "          0.1624, -0.0157, -0.1714, -0.5629, -0.5858, -0.1447,  0.1208, -0.3637,\n",
       "         -0.5638,  0.0727,  0.3334,  0.7510,  0.4024, -0.5213, -0.1455,  0.3036,\n",
       "         -0.4211, -0.3385,  0.0866,  0.6347,  0.0333, -0.0043,  0.2674, -0.4856,\n",
       "         -0.5593,  0.3388,  0.1180,  0.4711,  0.0298,  0.1481, -0.0278,  0.0591,\n",
       "          0.2866, -0.0259,  0.1199,  0.6027, -0.0036, -0.6107,  0.3720,  0.9449,\n",
       "         -0.0489,  0.2231, -0.0458, -0.2413, -0.0660, -0.2855,  0.1418, -0.6379,\n",
       "          0.2627,  0.3319,  0.0615, -0.0529, -0.2874, -0.5905, -0.6162,  0.7024,\n",
       "          0.0568, -0.0562, -0.6066,  0.2231, -0.6574, -0.3554,  0.2582, -0.6712,\n",
       "          0.3106,  0.4072, -0.9105,  0.0339,  0.0572, -0.1040, -0.6850,  0.1429,\n",
       "         -0.0555,  0.1584, -0.3255,  0.2598, -0.6312, -0.3726, -0.0231,  0.0603,\n",
       "          0.2755,  0.9272, -0.6815, -0.3056, -0.0874,  0.2438,  0.0497, -0.9177,\n",
       "         -1.2334, -0.2810, -0.1041,  0.0864, -0.0804,  0.3466, -0.7121, -0.4549,\n",
       "          0.4533, -0.2154,  0.4349,  0.6970, -0.5154, -0.5346, -0.8996,  0.1751,\n",
       "          0.6589,  0.3494,  0.2139,  0.8509,  0.2864, -0.0301, -0.0153, -0.0495,\n",
       "          0.5951,  0.5046,  0.0545,  0.0206,  0.5913, -0.2647, -0.5434, -0.1816]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0374e-02,  1.0539e-01,  7.2003e-01,  9.1016e-02,  5.8428e-01,\n",
       "         -6.2976e-01,  4.1820e-01, -6.0561e-01,  3.0891e-01,  1.5468e-01,\n",
       "         -7.2716e-01, -3.5082e-01, -5.1561e-01, -6.4436e-02,  3.3020e-01,\n",
       "          7.8816e-01, -9.7828e-01,  7.4846e-01,  1.0629e+00,  7.8854e-02,\n",
       "          6.5917e-01,  5.3075e-01, -5.8894e-01, -3.5543e-01,  2.8302e-01,\n",
       "          6.9419e-01,  8.0758e-01,  8.2078e-01,  2.2893e-01, -6.1503e-02,\n",
       "          9.1545e-02, -3.6115e-01, -4.7698e-01,  2.2208e-01, -4.6813e-01,\n",
       "          9.2734e-01, -3.1688e-01, -9.1254e-01,  1.0101e-01, -4.8914e-01,\n",
       "         -2.1969e-01, -4.5774e-01,  6.2094e-02, -4.9919e-01,  1.7547e-02,\n",
       "          1.7034e-01,  6.0430e-01, -2.9583e-01,  4.4978e-01, -4.9853e-01,\n",
       "         -1.1903e-01,  9.6551e-01,  6.9953e-01, -7.0943e-01, -6.0875e-02,\n",
       "         -2.2706e-01, -2.1787e-01, -3.0544e-02,  6.7560e-01,  1.8664e-01,\n",
       "          4.8871e-01, -3.9439e-01, -3.9275e-01, -4.9795e-01, -8.4439e-01,\n",
       "          1.1540e-01,  8.4235e-01,  3.7651e-01, -4.9501e-01, -2.6820e-01,\n",
       "          4.1439e-01, -7.0537e-01,  1.4541e-02, -2.5222e-01, -6.2856e-02,\n",
       "         -2.9689e-03,  5.1931e-01, -1.7651e-01,  5.4992e-01,  1.3773e-01,\n",
       "          4.9553e-01,  2.8977e-01, -5.8099e-02, -2.1235e-01, -4.3495e-01,\n",
       "          6.9923e-01, -2.0826e-02,  1.6350e-01, -5.9164e-01, -1.1076e-01,\n",
       "          1.1155e-01,  3.8022e-01, -1.8060e-01,  4.6128e-01,  1.9528e-01,\n",
       "          4.4396e-02,  3.7331e-01,  2.5786e-01,  8.9270e-01,  9.5394e-02,\n",
       "          4.8690e-01, -1.3272e+00,  5.7304e-01, -4.5859e-01, -6.4994e-01,\n",
       "         -1.4562e-01,  5.9126e-01,  4.0388e-02,  7.6137e-01,  9.7010e-02,\n",
       "         -7.6445e-01,  6.9232e-01, -5.3260e-01, -2.0409e-01, -5.1899e-01,\n",
       "          1.9439e-01,  2.1959e-01, -7.2534e-01, -3.4449e-01,  2.4535e-02,\n",
       "          7.0479e-02,  6.9547e-01, -2.2680e-02,  6.6607e-01,  5.4493e-01,\n",
       "          6.2570e-01, -2.9573e-01,  5.6083e-01, -4.7572e-01,  5.6331e-01,\n",
       "         -2.2514e-01, -4.2128e-02, -4.1432e-01,  1.0569e+00,  4.4682e-03,\n",
       "         -6.9926e-01, -1.8149e-01,  2.1620e-01,  3.4756e-01, -2.5272e-01,\n",
       "         -7.7894e-01,  2.8661e-01,  3.3344e-01, -4.9935e-01,  2.8651e-01,\n",
       "          9.7076e-02, -7.3569e-01, -8.6566e-01,  8.6024e-02,  9.9249e-01,\n",
       "         -1.9128e-01,  1.3724e+00,  7.4382e-01, -4.0797e-01,  6.6020e-02,\n",
       "          1.9612e-01, -7.3371e-02,  2.8384e-02, -2.3845e-01, -5.2690e-01,\n",
       "          2.6189e-03, -9.7564e-01, -6.4234e-01, -4.5121e-01,  1.5726e+00,\n",
       "         -1.0354e+00, -2.0089e-01, -2.4157e-01, -1.3826e-01,  4.8773e-01,\n",
       "         -2.8877e-02, -3.1132e-01, -6.5385e-02,  2.3019e-01, -1.2682e-01,\n",
       "          1.0515e+00,  7.9830e-02, -5.2014e-01,  3.5898e-01, -1.8010e-01,\n",
       "          3.8642e-01, -6.6962e-01, -4.3282e-01,  8.2818e-02, -6.3808e-01,\n",
       "         -3.0614e-01,  6.3276e-01,  7.1510e-01,  3.9584e-01, -8.5457e-02,\n",
       "         -3.2999e-01, -4.7935e-01,  2.6945e-01, -1.5469e-01,  7.1238e-01,\n",
       "         -3.3944e-01,  1.8352e-01, -3.2156e-01, -6.1207e-01,  2.1171e-01,\n",
       "         -6.8510e-02,  2.9892e-01, -6.4326e-01,  2.2024e-01, -1.5727e-01,\n",
       "         -1.5430e-01, -1.9166e-01,  4.5412e-01, -3.9299e-01,  8.7657e-01,\n",
       "          4.9138e-01,  4.5253e-02,  5.5011e-01, -5.0627e-01,  5.5357e-01,\n",
       "          1.6127e-01, -2.0711e-01, -1.8449e-01,  5.0325e-01, -5.1232e-01,\n",
       "         -1.5940e-01, -4.7483e-01,  8.1425e-01, -3.3099e-01,  3.7870e-01,\n",
       "          7.8630e-01,  1.8567e-01,  1.4735e-01, -8.1233e-02,  8.6242e-02,\n",
       "         -3.9975e-01, -1.7442e-01, -6.4140e-01,  5.3331e-01,  3.4584e-01,\n",
       "         -1.3365e+00,  4.8682e-01,  4.7026e-01, -7.9284e-01,  3.2278e-01,\n",
       "         -4.6455e-01,  1.8141e-01,  3.4140e-01,  2.5657e-01, -3.4852e-01,\n",
       "         -9.2374e-01,  1.0834e-01, -1.1081e-01, -6.0064e-01,  5.6395e-01,\n",
       "         -2.7875e-01,  1.8192e-01, -4.2401e-01, -1.0489e-02,  1.1482e-01,\n",
       "          3.2462e-01, -1.3302e+00,  5.4798e-01, -5.3133e-01,  2.7707e-01,\n",
       "         -8.6880e-02,  2.9965e-01, -1.0509e+00,  3.4976e-01,  3.4875e-01,\n",
       "         -3.6331e-01, -1.6605e-01,  2.3988e-02,  9.6566e-01,  6.6341e-02,\n",
       "          1.7517e-01,  1.8334e-01, -1.5644e-01, -8.3463e-01,  1.0763e-01,\n",
       "         -2.6239e-02,  1.5180e+00,  8.3439e-01, -3.0971e-01,  6.4052e-01,\n",
       "         -7.9341e-01,  6.2470e-01,  7.3580e-01,  2.9889e-01,  8.4064e-01,\n",
       "         -1.2573e+00, -1.2531e-01, -2.0665e-02, -5.7851e-01, -6.0116e-01,\n",
       "          2.3772e-01,  4.0924e-01, -4.3293e-01, -6.5853e-01,  6.3371e-01,\n",
       "          6.1141e-01, -1.1398e-01, -5.5702e-01, -2.7775e-01, -3.6235e-02,\n",
       "         -3.2795e-01,  5.6229e-01,  1.1271e+00, -5.6576e-01,  5.9613e-01,\n",
       "         -5.9395e-01,  3.8594e-01,  4.6890e-01, -1.1302e+00,  1.3151e+00,\n",
       "         -5.3014e-01,  2.5323e-01, -8.1218e-01, -4.8839e-01,  1.0405e+00,\n",
       "         -4.1913e-01,  6.7055e-02, -2.7442e-01,  2.0895e-01, -8.8452e-01,\n",
       "         -1.5987e-02, -4.6927e-01, -5.1136e-01, -7.6165e-01,  6.8113e-01,\n",
       "         -2.4012e-01,  7.0309e-02, -3.2243e-01,  2.5093e-02,  7.9075e-04,\n",
       "          1.5666e-01, -5.7990e-01,  1.0239e-01, -6.0689e-01,  2.0237e-01,\n",
       "          1.7554e-01, -4.6429e-01,  4.4538e-02,  8.1791e-01,  1.8449e-01,\n",
       "         -6.2924e-01, -2.0882e-01, -1.0915e-01,  3.1635e-01,  1.9751e-01,\n",
       "          1.1937e+00,  9.0076e-01, -5.0502e-01,  4.2382e-01, -2.1174e-01,\n",
       "          3.0665e-01, -6.8281e-02, -5.4842e-01,  3.0182e-01, -1.0656e-01,\n",
       "         -2.1885e-02, -7.3729e-02, -4.8967e-01, -7.1202e-01,  1.0775e-01,\n",
       "          3.8223e-01, -2.8243e-01,  8.4805e-02, -6.0732e-01, -2.1669e-01,\n",
       "         -5.5496e-01,  6.2904e-01,  6.3692e-01,  2.3593e-01,  4.7979e-01,\n",
       "         -1.9871e-01, -5.6929e-01, -1.6546e-01,  2.1910e-01, -1.8992e-01,\n",
       "         -1.4545e-01,  9.7936e-01, -1.5632e-01, -6.2958e-01, -8.6106e-01,\n",
       "         -6.8879e-01, -2.6240e-01, -1.0830e+00,  2.2116e-01,  6.3647e-01,\n",
       "         -1.7037e-01,  1.6788e-02,  1.5274e-01,  1.5535e-01,  2.4010e-01,\n",
       "         -7.4772e-02,  1.7888e-01,  1.9846e-01, -2.8479e-01, -5.8662e-01,\n",
       "         -7.3903e-01, -3.7134e-01, -5.2891e-01,  3.2919e-01, -4.1314e-01,\n",
       "         -4.1034e-01,  2.4471e-01,  3.8516e-01,  7.7858e-01,  1.6853e-01,\n",
       "         -6.7374e-01,  1.5648e-01,  5.5983e-01, -5.3663e-01, -6.2496e-01,\n",
       "          3.1280e-01,  3.8368e-01, -1.6161e-01,  2.0058e-01,  2.7066e-01,\n",
       "         -1.2600e-01, -5.4868e-01,  3.4345e-01,  5.3945e-01,  3.2634e-01,\n",
       "         -5.6693e-02,  5.7376e-01, -5.6176e-03,  2.6808e-01,  3.0081e-01,\n",
       "          4.8511e-02, -1.0485e-01,  4.2435e-01,  2.4949e-01, -5.4276e-01,\n",
       "          4.1855e-01,  1.0934e+00, -9.7075e-03,  3.7373e-01,  6.4745e-02,\n",
       "         -5.7922e-01, -3.9355e-01, -4.9335e-01,  2.0103e-01, -8.7879e-01,\n",
       "          1.8798e-01, -2.8534e-02, -6.1762e-03, -1.0686e-01, -5.2878e-01,\n",
       "         -2.1304e-01, -5.9275e-01,  8.1922e-01,  1.0837e-01,  1.4428e-02,\n",
       "         -8.1830e-01,  5.7609e-02, -4.5626e-01,  2.5720e-01,  3.3567e-01,\n",
       "         -5.4409e-01,  1.1470e-01,  1.1682e-03, -1.3572e+00,  5.1242e-02,\n",
       "          2.0882e-01,  3.3764e-01, -7.7289e-01,  2.0746e-01,  8.3944e-02,\n",
       "          3.5435e-01, -9.4491e-02,  1.1856e-01, -5.2017e-01, -1.4943e-01,\n",
       "         -7.6686e-02, -6.3925e-02,  2.1513e-01,  1.1685e+00, -8.0477e-01,\n",
       "         -4.1401e-01,  1.1263e-01,  6.8328e-02,  3.1192e-01, -7.3666e-01,\n",
       "         -1.3289e+00, -4.0839e-01, -2.6795e-01,  2.4848e-01, -3.7721e-01,\n",
       "          3.8721e-01, -8.7125e-01, -6.5576e-01,  5.5190e-01, -1.9362e-01,\n",
       "          6.0758e-01,  8.0595e-01, -6.9025e-01, -7.3367e-01, -1.3640e+00,\n",
       "          1.2882e-01,  7.9323e-01,  3.2324e-01, -2.2256e-01,  1.1726e+00,\n",
       "          1.5538e-01,  6.6513e-02, -1.4677e-01,  1.3396e-01,  6.9094e-01,\n",
       "          7.8288e-01, -6.1188e-02, -5.3103e-01,  4.7444e-01, -3.2808e-01,\n",
       "         -1.1688e-01, -1.3569e-02]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "if 'my_pd' in locals():\n",
    "    print('my_pd exists')\n",
    "else:\n",
    "    my_pd = pd.DataFrame()\n",
    "print(my_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
